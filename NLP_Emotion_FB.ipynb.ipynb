{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f2cf62-1f90-472a-8465-a5afc6a706da",
   "metadata": {},
   "source": [
    "# EmotiWave: Multilingual Sentiment & Theme Analysis of Social Media Reactions to Creative Content\n",
    "\n",
    "🎶 *A real-world NLP pipeline using BERT and SentenceTransformers to analyze emotional engagement with a Facebook music video.*\n",
    "\n",
    "---\n",
    "\n",
    "#### 🎵 Original Music Video\n",
    "\n",
    "This project analyzes viewer reactions to my singing performance, posted on Facebook. You can watch the original video by clicking this vibrant link below:\n",
    "\n",
    "👉 [**🎥 Watch My Singing Performance on Facebook**](https://www.facebook.com/sriyanka.sarkar.5/videos/722454450156983)\n",
    "\n",
    "The comments used in this analysis were collected directly from this post, making the emotional insights deeply personal and authentic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34964f-e759-4228-8157-47f1e7b6eeef",
   "metadata": {},
   "source": [
    "#### 📊 Project Overview\n",
    "\n",
    "I built a project called **EmotiWave** that analyzes emotional engagement with creative content. I collected viewer comments from my music video posted on Facebook, and used NLP to classify both sentiment and thematic resonance.\n",
    "\n",
    "- For **sentiment analysis**, I used a multilingual BERT model to rate emotional tone from 1 to 5 stars.\n",
    "- For **theme classification**, I used semantic similarity with SentenceTransformers to match comments to categories like *Artistic Praise* or *Nostalgia*.\n",
    "\n",
    "The result is a structured emotional map of audience reactions, which I visualized in a clean table. This project demonstrates my ability to apply AI to real-world, multilingual social data and extract meaningful insights from emotionally rich content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b0ea7-df1f-4906-8d06-118c53b34473",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde18df8-0e9f-4d45-8937-0f2e784f7479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (4.54.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (5.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentence-transformers torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cc2ec-b4c7-4275-99ce-c86436d087a0",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Comment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd7470d-fb46-4278-8a01-92d889d1159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data = [\n",
    "    {\"username\": \"Biki Roy\", \"comment\": \"Woooow your singing is always blessing\"},\n",
    "    {\"username\": \"Shekhar Majumdar\", \"comment\": \"Gorgeous\"},\n",
    "    {\"username\": \"Masum Sabnam\", \"comment\": \"Khub sundar. kmn achs Sriyanka?\"},\n",
    "    {\"username\": \"Manosi Mandal\", \"comment\": \"Onk din por tomar gan sunlam didi .. hostel room er kotha mone pore gelo .. kotooo gan sunechi tomar theke koto moja korechilm ❤️🤩\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9873de9d-fee5-4461-be63-19d9418ba48e",
   "metadata": {},
   "source": [
    "### Step 3: Load NLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8aefa02-89c2-42f4-aad8-5a568bc71846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (0.34.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub[hf_xet]) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub[hf_xet]) (1.1.7)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface_hub[hf_xet]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriya\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface_hub[hf_xet]) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub[hf_xet]\n",
    "# or\n",
    "#pip install hf_xet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20d3d5b-4275-4eba-ac86-f29b484b8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b58e24-2db8-4d0d-bb6c-496f714a1f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fac24745ba43a788b6057be17423cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Language:', options=('English', 'Bengali'), value='English')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "dropdown = widgets.Dropdown(options=['English', 'Bengali'], description='Language:')\n",
    "display(dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5803dec-f34c-4a12-8591-05acd322d467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"https://huggingface.co\").status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee5cbaa7-26d5-48f9-9b55-27c7cc59d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "translation_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3737044-985f-4a67-8004-b484126a277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment model failed to load: 'NoneType' object has no attribute 'endswith'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    translation_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"facebook/nllb-200-distilled-600M\", local_files_only=True\n",
    "    )\n",
    "    translation_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"facebook/nllb-200-distilled-600M\", local_files_only=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Translation model failed to load:\", e)\n",
    "\n",
    "try:\n",
    "    sentiment_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"cardiffnlp/twitter-xlm-roberta-base-sentiment\", local_files_only=True\n",
    "    )\n",
    "    sentiment_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"cardiffnlp/twitter-xlm-roberta-base-sentiment\", local_files_only=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Sentiment model failed to load:\", e)\n",
    "\n",
    "try:\n",
    "    topic_model = SentenceTransformer(\"all-MiniLM-L6-v2\", local_files_only=True)\n",
    "except Exception as e:\n",
    "    print(\"Topic model failed to load:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1181f4-e6dd-4a6b-9bf8-0def70760ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme Classification\n",
    "topic_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62849f6-e4da-4d4a-89c2-7d3d7202cd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8060e4bf-46e4-40e8-a2c4-15854bcb3053",
   "metadata": {},
   "source": [
    "### Step 4: Define Your Emotional Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "511bb2e5-efe9-42ae-be89-77c748d34717",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {\n",
    "    \"Emotional Impact\": \"Touched my heart\",\n",
    "    \"Artistic Praise\": \"Beautiful voice and singing\",\n",
    "    \"Lyrics & Composition\": \"Lyrics are deep and meaningful\",\n",
    "    \"Nostalgia\": \"Reminds me of old memories\",\n",
    "    \"Other\": \"General comment or unclear\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518051fd-5f6c-40f7-98d5-854ab7b6d200",
   "metadata": {},
   "source": [
    "### Step 5: Define the Theme Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee8bfe86-ce58-491a-a809-82064664f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def categorize_topic(text, topic_dict):\n",
    "    topic_texts = list(topic_dict.values())\n",
    "    topic_keys = list(topic_dict.keys())\n",
    "    embeddings = topic_model.encode(topic_texts, convert_to_tensor=True)\n",
    "    comment_embed = topic_model.encode(text, convert_to_tensor=True)\n",
    "    cos_scores = util.cos_sim(comment_embed, embeddings)[0]\n",
    "    top_idx = torch.argmax(cos_scores).item()\n",
    "    return topic_keys[top_idx], round(cos_scores[top_idx].item(), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7fe4a1-deb4-4713-87fc-bae4379ff37f",
   "metadata": {},
   "source": [
    "### Step 6: Run Theme Classification on Your Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "680f4b5f-3c8b-47d9-80b6-ee9b223f609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriya\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 Biki Roy\n",
      "💬 Comment: Woooow your singing is always blessing\n",
      "🎭 Theme: Artistic Praise (0.545)\n",
      "--------------------------------------------------\n",
      "👤 Shekhar Majumdar\n",
      "💬 Comment: Gorgeous\n",
      "🎭 Theme: Artistic Praise (0.398)\n",
      "--------------------------------------------------\n",
      "👤 Masum Sabnam\n",
      "💬 Comment: Khub sundar. kmn achs Sriyanka?\n",
      "🎭 Theme: Artistic Praise (0.141)\n",
      "--------------------------------------------------\n",
      "👤 Manosi Mandal\n",
      "💬 Comment: Onk din por tomar gan sunlam didi .. hostel room er kotha mone pore gelo .. kotooo gan sunechi tomar theke koto moja korechilm ❤️🤩\n",
      "🎭 Theme: Nostalgia (0.09)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in comments_data:\n",
    "    user = entry[\"username\"]\n",
    "    original = entry[\"comment\"]\n",
    "    theme, score = categorize_topic(original, topic_dict)\n",
    "    \n",
    "    print(f\"👤 {user}\")\n",
    "    print(f\"💬 Comment: {original}\")\n",
    "    print(f\"🎭 Theme: {theme} ({score})\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4243b51b-79b6-453d-b4f2-da1bb4adb19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Theme Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biki Roy</td>\n",
       "      <td>Woooow your singing is always blessing</td>\n",
       "      <td>Artistic Praise</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shekhar Majumdar</td>\n",
       "      <td>Gorgeous</td>\n",
       "      <td>Artistic Praise</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masum Sabnam</td>\n",
       "      <td>Khub sundar. kmn achs Sriyanka?</td>\n",
       "      <td>Artistic Praise</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manosi Mandal</td>\n",
       "      <td>Onk din por tomar gan sunlam didi .. hostel ro...</td>\n",
       "      <td>Nostalgia</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               User                                            Comment  \\\n",
       "0          Biki Roy             Woooow your singing is always blessing   \n",
       "1  Shekhar Majumdar                                           Gorgeous   \n",
       "2      Masum Sabnam                    Khub sundar. kmn achs Sriyanka?   \n",
       "3     Manosi Mandal  Onk din por tomar gan sunlam didi .. hostel ro...   \n",
       "\n",
       "             Theme  Theme Score  \n",
       "0  Artistic Praise        0.545  \n",
       "1  Artistic Praise        0.398  \n",
       "2  Artistic Praise        0.141  \n",
       "3        Nostalgia        0.090  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for entry in comments_data:\n",
    "    user = entry[\"username\"]\n",
    "    original = entry[\"comment\"]\n",
    "    theme, score = categorize_topic(original, topic_dict)\n",
    "    \n",
    "    results.append({\n",
    "        \"User\": user,\n",
    "        \"Comment\": original,\n",
    "        \"Theme\": theme,\n",
    "        \"Theme Score\": score\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "df = pd.DataFrame(results)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f21d2-1593-403b-812d-8f7764d58a0d",
   "metadata": {},
   "source": [
    "### Step 7: Load Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13feb6b1-62d8-4619-9477-ad2b7e29d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44c02a496fa4519ab4a2fa6f5a6e5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  83%|########3 | 556M/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriya\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sriya\\.cache\\huggingface\\hub\\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load sentiment model (no tiktoken dependency)\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Define sentiment analysis function\n",
    "def analyze_sentiment(text):\n",
    "    inputs = sentiment_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = sentiment_model(**inputs)\n",
    "    scores = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n",
    "    rating = torch.argmax(scores).item() + 1  # Ratings: 1 to 5\n",
    "    return f\"{rating} stars\", round(scores.max().item(), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e961694-a8b9-42d5-b7b4-e8783b01b60f",
   "metadata": {},
   "source": [
    "### Step 9: Combine Sentiment & Theme in Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b4c6d6e-9c9e-4b34-9727-3cd865efa624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriya\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Theme Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biki Roy</td>\n",
       "      <td>Woooow your singing is always blessing</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.708</td>\n",
       "      <td>Artistic Praise</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shekhar Majumdar</td>\n",
       "      <td>Gorgeous</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.838</td>\n",
       "      <td>Artistic Praise</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masum Sabnam</td>\n",
       "      <td>Khub sundar. kmn achs Sriyanka?</td>\n",
       "      <td>1 stars</td>\n",
       "      <td>0.353</td>\n",
       "      <td>Artistic Praise</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manosi Mandal</td>\n",
       "      <td>Onk din por tomar gan sunlam didi .. hostel ro...</td>\n",
       "      <td>1 stars</td>\n",
       "      <td>0.449</td>\n",
       "      <td>Nostalgia</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               User                                            Comment  \\\n",
       "0          Biki Roy             Woooow your singing is always blessing   \n",
       "1  Shekhar Majumdar                                           Gorgeous   \n",
       "2      Masum Sabnam                    Khub sundar. kmn achs Sriyanka?   \n",
       "3     Manosi Mandal  Onk din por tomar gan sunlam didi .. hostel ro...   \n",
       "\n",
       "  Sentiment  Sentiment Score            Theme  Theme Score  \n",
       "0   5 stars            0.708  Artistic Praise        0.545  \n",
       "1   5 stars            0.838  Artistic Praise        0.398  \n",
       "2   1 stars            0.353  Artistic Praise        0.141  \n",
       "3   1 stars            0.449        Nostalgia        0.090  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for entry in comments_data:\n",
    "    user = entry[\"username\"]\n",
    "    original = entry[\"comment\"]\n",
    "    \n",
    "    sentiment, sentiment_score = analyze_sentiment(original)\n",
    "    theme, theme_score = categorize_topic(original, topic_dict)\n",
    "    \n",
    "    results.append({\n",
    "        \"User\": user,\n",
    "        \"Comment\": original,\n",
    "        \"Sentiment\": sentiment,\n",
    "        \"Sentiment Score\": sentiment_score,\n",
    "        \"Theme\": theme,\n",
    "        \"Theme Score\": theme_score\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e90ca1-f788-410e-914e-e77b5b43e0ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21095f0c-2479-45ee-a05d-d22cd7ac5eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
